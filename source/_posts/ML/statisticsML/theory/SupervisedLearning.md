---
title: 监督学习概论
p: ML/statisticsML/theory/SupervisedLearning.md
date: 2019-01-06 01:39:51
tags: 
- 统计机器学习
- 监督学习
categories: 
- 机器学习
- 统计机器学习
thumbnail: /images/thumbnails/Sunrise/Sunrise001.jpeg
---
监督学习(supervised learning)的任务是学习一个模型，使模型能够对任意给定的输入，对其相应的输出做出一个好的预测。
监督学习是及其重要的统计学习分支，也是统计学习中内容最丰富，应用最广泛的部分
<!-- more -->

### 监督学习的基本概念
* 输入空间，特征空间，输出空间
  * 输入空间：输入所有可能的取值的集合
  * 特征空间：每个具体的输入是一个实例，通常由特征向量(feature vector)表示，这时，所有特征向量存在的空间称之为特征空间(feature space)
    * 特征空间的每一纬对应与一个特征
  * 输出空间：输出所有可能的取值的集合
* 输入空间与输出空间的关系
  * 输入与输出空间可以是有限元素的集合，也可以是整个欧式空间
  * 输入与输出空间可以是同一空间，也可以是不同的空间
  * 通常输出空间远远小于输入空间
* 输入空间与特征空间
  * 有时假设输入空间与特征空间为相同空间
  * 有时假设输入空间与特征空间为不同的空间，将实例(输入)映射到特征空间。
* **模型实际上都是定义在特征空间上的**
* 输入实例\\(x\\)的特征向量记作$$x=(x^{(1)},x^{(2)},\dots,x^{(i)},\dots,x^{(n)})^T$$
* 训练数据由输入(或特征向量)与输出对组成，训练集通常表示为$$\mathbf{T}={(x_1,y_1),(x_2,y_2),\dots,(x_n,y_n)}$$
* 测试数据也由输入(或特征向量)与输出对组成，又称之为样本或者样本点
* 输入变量\\(X\\)和输出变量\\(Y\\)可以有不同的类型(连续或者是离散的)，人们习惯根据输入变量和输出变量的类型定义以下几种预测任务类型
  * **回归问题**：输入变量和输出变量均为连续变量的预测问题
  * **分类问题**：输出变量为有限个离散变量的预测任务
  * **标注问题**：输入变量与输出变量均为变量序列的预测问题
* 联合概率分布
  * 监督学习假设输入与输出的随机变量\\(X\\)和\\(Y\\)遵循联合概率分布\\(P(X,Y)\\)，\\(P(X,Y)\\)表示分布函数，或者分布密度函数。
  * 在学习过程中，假定这一联合概率分布存在，但对学习系统来说，联合概率分布的具体定义是未知的。
  * 训练集数据与测试集数据被看做是依联合改了分布\\(P(X,Y)\\)独立同分布产生的。
  * 统计学习假设数据存在一定的统计规律，\\(X\\)和\\(Y\\)遵循联合概率分布\\(P(X,Y)\\)就是监督学习关于数据的基本假设
* 假设空间
  * 假设空间是指输入空间到输出空间的映射的集合。
  * 假设空间的设定代表学习范围的确定。

### 问题的形式化
* 在学习过程中，学习系统利用给定的训练集数据，通过学习，训练得到一个模型，表示为**条件概率分布**\\(\widehat{P}(Y|X)\\)或**决策函数**\\(Y=\widehat{f}(X)\\)
* **条件概率分布**\\(\widehat{P}(Y|X)\\)或**决策函数**\\(Y=\widehat{f}(X)\\)描述输入与输出随机变量之间的映射关系

### 统计学习三要素
$$统计学习方法=模型+策略+算法$$
* 模型
  * 在监督学习中，模型就是所要学习的条件概率分布或决策函数。
  * 模型的**假设空间**包含所有可能的条件概率分布或决策函数。
  * 假设空间中的模型一般有无穷多个
    * **假设空间**可以定义为决策函数的集合:$$\mathbf{F}=\\{f|Y=f(X)\\}$$\\(X\\)与\\(Y\\)是定义在输入空间\\(X\\)和输出空间\\(Y\\)的随机变量，这时\\(F\\)通常是由一个参数向量决定的函数族:$$\mathbf{F}=\\{f|Y=f_{\theta}(X),\theta\in\mathbf{R}^n\\}$$参数向量\\(\theta\\)取值于\\(n\\)维度欧式空间\\(\mathbf{R}^n\\)，称为参数空间
    * **假设空间**也可以定义为条件概率的集合:$$\mathbf{F}=\\{P|P(Y|X)\\}$$\\(X\\)与\\(Y\\)是定义在输入空间\\(X\\)和输出空间\\(Y\\)的随机变量，这时\\(F\\)通常是由一个参数向量决定的条件概率分布族:$$\mathbf{F}=\\{P|P_{\theta}(Y|X),\theta\in\mathbf{R}^n\\}$$参数向量\\(\theta\\)取值于\\(n\\)维度欧式空间\\(\mathbf{R}^n\\)，也称为参数空间
  * 通常称由**决策函数表示的模型为非概率模型**，**条件概率表示的模型为概率模型**
* 策略
  * 有了模型的假设空间之后，接下来考虑按照什么样的准则学习或者选择最优的模型。
  * 损失函数(loss function)也叫代价函数(cost function)：损失函数/代价函数度量模型一次预测的好坏，损失函数是\\(f(X)\\)和\\(Y\\)的非负实值函数，记作\\(L(Y,f(X))\\)，损失函数值越小，模型就越好
    * 统计学习常用的损失函数有以下几种:
      * 0-1损失函数(0-1 loss function)$$L(Y,f(X))=
      \begin{cases}
      1, & Y \ne f(X) \\\\
      0, & Y = f(X)
      \end{cases}$$
      * 平方损失函数$$L(Y,f(X))=(Y-f(X))^2$$
      * 绝对损失函数$$L(Y,f(X))=|Y-f(X)|$$
      * 对数损失函数/对数似然损失函数$$L(Y,P(Y|X))=-\log{P(Y|X)}$$
  * 风险函数：风险函数度量平均意义下模型预测的好坏，也就是损失函数的期望$$\mathbf{R}_{exp}(f)=E_p[L(Y,f(X))]=\int_{x*y}L(y,f(x))P(x,y)dxdy$$
* 算法


## 注:
  1. 本文多参考自《统计学习方法》，李航著，偏于个人学习笔记的整理。
